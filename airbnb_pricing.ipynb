{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for custom functions\n",
    "import os\n",
    "import sys\n",
    "# import sys; sys.path.insert(0, '..')\n",
    "# from lib.custom_functions import * \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Functions\n",
    "Custom functions for data processing and preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean(s: pd.Series):\n",
    "    return s.mean()\n",
    "\n",
    "def median(s: pd.Series):\n",
    "    return s.median()\n",
    "\n",
    "def drop_features(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df = df.drop(columns, axis=1)\n",
    "    return df\n",
    "\n",
    "def bool_to_binary(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    for column in columns:\n",
    "        local_kwargs = {column : lambda df: df[column].astype(str).str.replace('t', '1').replace('f', '0').replace('True', '1').replace('False', '0').astype(int)}\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .assign(**local_kwargs)\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "def process_neighbourhoods(df: pd.DataFrame, quantile: float=0.75) -> pd.DataFrame:\n",
    "    if os.path.isfile('data/neighbourhoods_to_keep.csv'):\n",
    "        print('process_neighbourhoods -> reading neighbourhoods_to_keep from file')\n",
    "        neighbourhoods_to_keep = pd.read_csv('data/neighbourhoods_to_keep.csv')\n",
    "        \n",
    "    else:\n",
    "        print('process_neighbourhoods -> processing neighbourhoods_to_keep')\n",
    "        yf = df.groupby(by=['neighbourhood']).id.count().sort_values(ascending=False).reset_index()\n",
    "        neighbourhoods_to_keep = (\n",
    "            pd.DataFrame(yf.loc[yf.id > yf.id.quantile(q=quantile), 'neighbourhood'])\n",
    "            .assign(neighbourhood_to_keep=lambda df: df['neighbourhood'])\n",
    "            .drop('neighbourhood', axis=1)\n",
    "        )\n",
    "        neighbourhoods_to_keep.to_csv('data/neighbourhoods_to_keep.csv')\n",
    "        \n",
    "    df = (\n",
    "        df\n",
    "        .merge(neighbourhoods_to_keep, how='left', left_on='neighbourhood', right_on='neighbourhood_to_keep')\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "        \n",
    "def fill_na(df: pd.DataFrame, replacements: dict) -> pd.DataFrame:\n",
    "    for k, v in replacements.items():\n",
    "\n",
    "        if callable(v):\n",
    "            value = v(df[k])\n",
    "        else:\n",
    "            value = v\n",
    "        \n",
    "        local_kwargs = {k : lambda df: df[k].fillna(value)}\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .assign(**local_kwargs)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df = pd.get_dummies(\n",
    "        df, columns=columns, prefix='', prefix_sep=''\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_host_response_rate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = (\n",
    "        df\n",
    "        .assign(host_response_rate=lambda df: df.host_response_rate.str.replace('%', '').astype(float))\n",
    "        .assign(host_response_class=lambda df: pd.cut(df.host_response_rate, \n",
    "                                                    bins=[0, 75, 80, 85, 90, 95, 100.00], \n",
    "                                                    labels=['very_low',\n",
    "                                                            'low',\n",
    "                                                            'medium',\n",
    "                                                            'high',\n",
    "                                                            'very_high',\n",
    "                                                            'best'], \n",
    "                                                    include_lowest=True))\n",
    "        .assign(host_response_class=lambda df: df.host_response_class.cat.add_categories('other').fillna('other'))\n",
    "        .drop('host_response_rate', axis=1)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_review_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = (\n",
    "    df\n",
    "        .assign(first_review=lambda df: pd.to_datetime(df.first_review))\n",
    "        .assign(last_review=lambda df: pd.to_datetime(df.last_review))\n",
    "        .assign(host_since=lambda df: pd.to_datetime(df.host_since))\n",
    "        .assign(today=[date.today()]*len(df.index))\n",
    "        .assign(today=lambda df: pd.to_datetime(df.today))\n",
    "        .assign(days_since_first_review=lambda df: (df.today - df.first_review).dt.days)\n",
    "        .assign(days_since_last_review=lambda df: (df.today - df.last_review).dt.days)\n",
    "        .assign(days_host_since=lambda df: (df.today - df.host_since).dt.days)\n",
    "        .assign(first_review_class=lambda df: pd.cut(df.days_since_first_review, \n",
    "                                                    bins=[0, 1095, 1280, 1460, 1645, 1830, max(df.days_since_first_review)], \n",
    "                                                    labels=['0y-3y',\n",
    "                                                            '3y-3y6m',\n",
    "                                                            '3y6m-4y',\n",
    "                                                            '4y-4y6m',\n",
    "                                                            '4y6m-5y',\n",
    "                                                            '5y'], \n",
    "                                                    include_lowest=True))\n",
    "        .assign(last_review_class=lambda df: pd.cut(df.days_since_last_review, \n",
    "                                                    bins=[0, 1095, 1220, 1460, 1645, 1830, max(df.days_since_first_review)], \n",
    "                                                    labels=['0y-3y',\n",
    "                                                            '3y-3y6m',\n",
    "                                                            '3y6m-4y',\n",
    "                                                            '4y-4y6m',\n",
    "                                                            '4y6m-5y',\n",
    "                                                            '5y'], \n",
    "                                                    include_lowest=True))\n",
    "        .assign(first_review_class=lambda df: df.first_review_class.cat.add_categories('other').fillna('other'))\n",
    "        .assign(last_review_class=lambda df: df.last_review_class.cat.add_categories('other').fillna('other'))\n",
    "        .assign(days_host_since=lambda df: df.days_host_since.fillna(1))\n",
    "        .drop(['first_review', 'last_review', 'today', 'days_since_first_review', 'days_since_last_review', 'host_since'], axis=1)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_amenities(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    amenities_to_keep = []\n",
    "    \n",
    "    if os.path.isfile('data/amenities_to_keep'):\n",
    "        print('process_amenities -> reading amenities_to_keep from file')\n",
    "        with open('data/amenities_to_keep', 'r') as f: \n",
    "            reader = csv.reader(f)\n",
    "\n",
    "            for row in reader:\n",
    "                amenities_to_keep = row\n",
    "            \n",
    "    if not amenities_to_keep:\n",
    "        print('process_amenities -> processing amenities_to_keep')\n",
    "        amenities = [x.strip() for x in \", \".join(list(df.amenities)).replace('{', '').replace('}', '').replace('\"', '').replace('TV', '').split(',')]\n",
    "\n",
    "        amenities_counter = {}\n",
    "        for amenity in amenities:\n",
    "            if amenity in amenities_counter.keys():\n",
    "                amenities_counter[amenity] += 1\n",
    "            else:\n",
    "                amenities_counter[amenity] = 1\n",
    "\n",
    "        amenities_counter_sorted = {k: v for k, v in sorted(amenities_counter.items(), key=lambda item: item[1])}\n",
    "\n",
    "        amenities_to_keep = []\n",
    "        records_count = (len(amenities_counter_sorted) + 0.001)\n",
    "        for i, e in (enumerate(amenities_counter_sorted.items())):\n",
    "            if (i*100.0/records_count > 20 or i*100.0/records_count < 80) \\\n",
    "            and (e[1] > 2) \\\n",
    "            and (\"translation missing\" not in e[0]) \\\n",
    "            and (e[0] != ''):\n",
    "                amenities_to_keep.append(e[0])\n",
    "                \n",
    "        with open('data/amenities_to_keep', 'w') as f: \n",
    "            print('process_amenities -> writing amenities_to_keep to file')\n",
    "            write = csv.writer(f) \n",
    "            write.writerow(amenities_to_keep)\n",
    "                \n",
    "        \n",
    "            \n",
    "    for amenity in amenities_to_keep:\n",
    "        df[amenity] = df.apply(lambda row: 1 if amenity in row.amenities else 0, axis=1)\n",
    "        \n",
    "    df = df.drop(['amenities'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_property_type(df: pd.DataFrame, column: str, replacements: dict) -> pd.DataFrame:\n",
    "    local_kwargs = {column : lambda df: df[column].replace(replacements)}\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .assign(**local_kwargs)\n",
    "    )\n",
    "    \n",
    "    df.loc[~df.property_type.isin(['House', 'Apartment']), 'property_type'] = 'other'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Cleaned data preparation pipeline for easier handling and maintenance.\n",
    "\n",
    "We save the training attributes, such as which amenities and neighborhoods to keep from the training set in order to use the same ones on the new unseen test set.\n",
    "\n",
    "A file with the training data processed is saved for just running the pipeline once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_pipeline(df: pd.DataFrame, data_path: str) -> pd.DataFrame:\n",
    "    \n",
    "    df_processed = (\n",
    "    df\n",
    "    .pipe(drop_features, columns=['latitude', 'longitude', 'name', 'thumbnail_url', 'zipcode', 'host_has_profile_pic', 'description'])\n",
    "    .pipe(fill_na, replacements={'neighbourhood': 'other'})\n",
    "    .pipe(process_neighbourhoods, quantile=0.8)\n",
    "    .pipe(drop_features, columns=['neighbourhood'])\n",
    "    .pipe(fill_na, replacements={'number_of_reviews': 0,\n",
    "                                 'bedrooms': 0,\n",
    "                                 'review_scores_rating': mean,\n",
    "                                 'beds': median,\n",
    "                                 'bathrooms': median,\n",
    "                                 'accommodates': median,\n",
    "                                 'neighbourhood_to_keep': 'other'})\n",
    "    .pipe(bool_to_binary, columns=['cleaning_fee', 'host_identity_verified', 'instant_bookable'])\n",
    "    .pipe(process_property_type, column='property_type', replacements={'Townhouse': 'House',\n",
    "                                                                       'Bungalow': 'House',\n",
    "                                                                       'Cottage': 'House',\n",
    "                                                                       'Villa': 'House',\n",
    "                                                                       'Tiny house': 'House',\n",
    "                                                                       'Chalet': 'House',\n",
    "                                                                       'Serviced apartment': 'Apartment',\n",
    "                                                                       'Loft': 'Apartment',\n",
    "                                                                       'Condominium': 'Apartment'})\n",
    "    .pipe(process_host_response_rate)\n",
    "    .pipe(process_review_dates)\n",
    "    .pipe(process_amenities)\n",
    "    .pipe(one_hot_encoder, \n",
    "          columns=['instant_bookable', \n",
    "                   'host_identity_verified', \n",
    "                   'city', \n",
    "                   'cleaning_fee',\n",
    "                   'cancellation_policy', \n",
    "                   'bed_type', \n",
    "                   'room_type', \n",
    "                   'host_response_class', \n",
    "                   'neighbourhood_to_keep', \n",
    "                   'property_type',\n",
    "                   'first_review_class',\n",
    "                   'last_review_class'])\n",
    "\n",
    "    )\n",
    "        \n",
    "    columns_to_drop = [col for col in df_processed.columns if 'Unnamed' in col]\n",
    "    df_processed = df_processed.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    df_processed.to_csv(data_path)\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>days_host_since</th>\n",
       "      <th>Roll-in shower with chair</th>\n",
       "      <th>...</th>\n",
       "      <th>4y6m-5y</th>\n",
       "      <th>5y</th>\n",
       "      <th>other.3</th>\n",
       "      <th>0y-3y.1</th>\n",
       "      <th>3y-3y6m.1</th>\n",
       "      <th>3y6m-4y.1</th>\n",
       "      <th>4y-4y6m.1</th>\n",
       "      <th>4y6m-5y.1</th>\n",
       "      <th>5y.1</th>\n",
       "      <th>other.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6901257</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6304928</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7919400</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13418779</td>\n",
       "      <td>6.620073</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.067365</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2062.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808709</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price  accommodates  bathrooms  number_of_reviews  \\\n",
       "0   6901257   5.010635             3        1.0                  2   \n",
       "1   6304928   5.129899             7        1.0                  6   \n",
       "2   7919400   4.976734             5        1.0                 10   \n",
       "3  13418779   6.620073             4        1.0                  0   \n",
       "4   3808709   4.744932             2        1.0                  4   \n",
       "\n",
       "   review_scores_rating  bedrooms  beds  days_host_since  \\\n",
       "0            100.000000       1.0   1.0           3181.0   \n",
       "1             93.000000       3.0   3.0           1270.0   \n",
       "2             92.000000       1.0   3.0           1507.0   \n",
       "3             94.067365       2.0   2.0           2062.0   \n",
       "4             40.000000       0.0   1.0           2111.0   \n",
       "\n",
       "   Roll-in shower with chair   ...     4y6m-5y  5y  other.3  0y-3y.1  \\\n",
       "0                          0   ...           0   0        0        0   \n",
       "1                          0   ...           0   0        0        0   \n",
       "2                          0   ...           0   0        0        0   \n",
       "3                          0   ...           0   0        1        0   \n",
       "4                          0   ...           0   1        0        0   \n",
       "\n",
       "   3y-3y6m.1  3y6m-4y.1  4y-4y6m.1  4y6m-5y.1  5y.1  other.4  \n",
       "0          0          0          1          0     0        0  \n",
       "1          1          0          0          0     0        0  \n",
       "2          1          0          0          0     0        0  \n",
       "3          0          0          0          0     0        1  \n",
       "4          0          1          0          0     0        0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('data/train_processed.csv'):\n",
    "    df_train_processed = pd.read_csv('data/train_processed.csv')\n",
    "    \n",
    "else:\n",
    "    df_train = pd.read_csv('data/train.csv')\n",
    "    df_train_processed = data_process_pipeline(df_train, 'data/train_processed.csv')\n",
    "\n",
    "columns_to_drop = [col for col in df_train_processed.columns if 'Unnamed' in col]\n",
    "df_train_processed = df_train_processed.drop(columns_to_drop, axis=1)\n",
    "\n",
    "print(f'Number of features: {len(df_train_processed.columns) - 1}')\n",
    "df_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_scores(y_test, pred):\n",
    "    return (np.sqrt(mean_squared_error(y_test[[regressand]], pred))), r2_score(y_test[[regressand]], pred)\n",
    "\n",
    "def get_model_yf(y_test, pred, model, regressand='log_price'):\n",
    "    mod_pred_df = (\n",
    "    pd.DataFrame(pred, columns=[regressand])\n",
    "    )\n",
    "    mod_pred_df['class'] = 'predicted'\n",
    "    \n",
    "    mod_yf = pd.concat([mod_pred_df, y_test])\n",
    "    mod_yf['model'] = model\n",
    "    \n",
    "    return mod_yf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test and Holded Data\n",
    "We split the training set intro *train* and *test*, and we *hold* the provided test set to simulate 100% unseen data. Given that there are some parameters that were tuned with trained data and these same parameters should be used in production environment when predicting unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_neighbourhoods -> reading neighbourhoods_to_keep from file\n",
      "process_amenities -> reading amenities_to_keep from file\n",
      "Number of features: 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>days_host_since</th>\n",
       "      <th>Roll-in shower with chair</th>\n",
       "      <th>Paid parking off premises</th>\n",
       "      <th>...</th>\n",
       "      <th>4y6m-5y</th>\n",
       "      <th>5y</th>\n",
       "      <th>other</th>\n",
       "      <th>0y-3y</th>\n",
       "      <th>3y-3y6m</th>\n",
       "      <th>3y6m-4y</th>\n",
       "      <th>4y-4y6m</th>\n",
       "      <th>4y6m-5y</th>\n",
       "      <th>5y</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3895911</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>97.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9710289</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9051635</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3423.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708374</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>94.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>626296</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.01155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  accommodates  bathrooms  number_of_reviews  review_scores_rating  \\\n",
       "0  3895911             2        1.0                  6              97.00000   \n",
       "1  9710289             3        1.0                  2              80.00000   \n",
       "2  9051635             1        1.0                  2             100.00000   \n",
       "3   708374             1        1.0                  7              94.00000   \n",
       "4   626296             2        1.0                  0              94.01155   \n",
       "\n",
       "   bedrooms  beds  days_host_since  Roll-in shower with chair  \\\n",
       "0       1.0   1.0           1585.0                          0   \n",
       "1       1.0   1.0           2568.0                          0   \n",
       "2       1.0   1.0           3423.0                          0   \n",
       "3       0.0   1.0           3093.0                          0   \n",
       "4       1.0   1.0           1799.0                          0   \n",
       "\n",
       "   Paid parking off premises  ...    4y6m-5y  5y  other  0y-3y  3y-3y6m  \\\n",
       "0                          0  ...          0   0      0      0        0   \n",
       "1                          0  ...          0   0      0      0        0   \n",
       "2                          0  ...          0   0      0      0        0   \n",
       "3                          0  ...          0   1      0      0        0   \n",
       "4                          0  ...          0   0      1      0        0   \n",
       "\n",
       "   3y6m-4y  4y-4y6m  4y6m-5y  5y  other  \n",
       "0        1        0        0   0      0  \n",
       "1        0        1        0   0      0  \n",
       "2        0        1        0   0      0  \n",
       "3        1        0        0   0      0  \n",
       "4        0        0        0   0      1  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('data/test_processed.csv'):\n",
    "    df_test_processed = pd.read_csv('data/test_processed.csv')\n",
    "    \n",
    "else:\n",
    "    df_test = pd.read_csv('data/test.csv')\n",
    "    df_test_processed = data_process_pipeline(df_test, 'data/test_processed.csv')\n",
    "\n",
    "columns_to_drop = [col for col in df_test_processed.columns if 'Unnamed' in col]\n",
    "df_test_processed = df_test_processed.drop(columns_to_drop, axis=1)\n",
    "\n",
    "print(f'Number of features: {len(df_test_processed.columns) - 1}')\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressand = 'log_price'\n",
    "X = df_train_processed.loc[:, df_train_processed.columns != regressand]\n",
    "y = df_train_processed.loc[:, df_train_processed.columns == regressand]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=9)\n",
    "\n",
    "y_test['class'] = 'y_test'\n",
    "yf = pd.DataFrame() # for saving model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.421129596805214\n",
      "Test R2: 0.654799662481068\n"
     ]
    }
   ],
   "source": [
    "lin_reg_mod = LinearRegression()\n",
    "lin_reg_mod.fit(X_train, y_train)\n",
    "\n",
    "pred = lin_reg_mod.predict(X_test)\n",
    "\n",
    "#Model Scores\n",
    "test_set_rmse, test_set_r2 = get_model_scores(y_test[[regressand]], pred)\n",
    "\n",
    "# for plotting distributions\n",
    "lin_reg_mod_yf = get_model_yf(y_test, pred, model='linear_regression')\n",
    "\n",
    "# model results\n",
    "print(f'Test RMSE: {test_set_rmse}')\n",
    "print(f'Test R2: {test_set_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.7138708349402949\n",
      "Test R2: 0.008074714303584196\n"
     ]
    }
   ],
   "source": [
    "lasso_mod = Lasso()\n",
    "lasso_mod.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso_mod.predict(X_test)\n",
    "\n",
    "#Model Scores\n",
    "test_set_rmse, test_set_r2 = get_model_scores(y_test[[regressand]], pred)\n",
    "\n",
    "# for plotting distributions\n",
    "lasso_mod_yf = get_model_yf(y_test, pred, model='lasso_regression')\n",
    "\n",
    "# model results\n",
    "print(f'Test RMSE: {test_set_rmse}')\n",
    "print(f'Test R2: {test_set_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.42110428156335833\n",
      "Test R2: 0.6548411630901056\n"
     ]
    }
   ],
   "source": [
    "ridge_mod = Ridge()\n",
    "ridge_mod.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge_mod.predict(X_test)\n",
    "\n",
    "#Model Scores\n",
    "test_set_rmse, test_set_r2 = get_model_scores(y_test[[regressand]], pred)\n",
    "\n",
    "# for plotting distributions\n",
    "ridge_mod_yf = get_model_yf(y_test, pred, model='ridge_regression')\n",
    "\n",
    "# model results\n",
    "print(f'Test RMSE: {test_set_rmse}')\n",
    "print(f'Test R2: {test_set_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "multi_nn_mod = MLPRegressor(solver='sgd')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "multi_nn_mod.fit(X_train, y_train)\n",
    "\n",
    "pred = multi_nn_mod.predict(X_test)\n",
    "\n",
    "#Model Scores\n",
    "test_set_rmse, test_set_r2 = get_model_scores(y_test[[regressand]], pred)\n",
    "\n",
    "# for plotting distributions\n",
    "multi_nn_mod_yf = get_model_yf(y_test, pred, model='multi_nn_regression')\n",
    "\n",
    "# model results\n",
    "print(f'Test RMSE: {test_set_rmse}')\n",
    "print(f'Test R2: {test_set_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot, actual vs predicted price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = (\n",
    "    pd.concat([lin_reg_mod_yf, ridge_mod_yf, lasso_mod_yf, multi_nn_mod_yf])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "sns.violinplot(x='model',\n",
    "               y='log_price',\n",
    "               hue='class',\n",
    "               data=yf,\n",
    "               split=True,\n",
    "               ax=ax)\n",
    "\n",
    "plt.savefig('figures/eta_pre_violin.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
