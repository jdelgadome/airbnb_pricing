{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# for custom functions\n",
    "import os\n",
    "import sys\n",
    "# import sys; sys.path.insert(0, '..')\n",
    "# from lib.custom_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "def mean(s: pd.Series):\n",
    "    return s.mean()\n",
    "\n",
    "def median(s: pd.Series):\n",
    "    return s.median()\n",
    "\n",
    "def drop_features(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df = df.drop(columns, axis=1)\n",
    "    return df\n",
    "\n",
    "def bool_to_binary(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    for column in columns:\n",
    "        local_kwargs = {column : lambda df: df[column].astype(str).str.replace('t', '1').replace('f', '0').replace('True', '1').replace('False', '0').astype(int)}\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .assign(**local_kwargs)\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "def process_neighbourhoods(df: pd.DataFrame, quantile: float=0.75) -> pd.DataFrame:\n",
    "    if os.path.isfile('data/neighbourhoods_to_keep.csv'):\n",
    "        neighbourhoods_to_keep = pd.read_csv('data/neighbourhoods_too_keep.csv')\n",
    "        \n",
    "    else:\n",
    "        yf = df.groupby(by=['neighbourhood']).id.count().sort_values(ascending=False).reset_index()\n",
    "        neighbourhoods_to_keep = (\n",
    "            pd.DataFrame(yf.loc[yf.id > yf.id.quantile(q=quantile), 'neighbourhood'])\n",
    "            .assign(neighbourhood_to_keep=lambda df: df['neighbourhood'])\n",
    "            .drop('neighbourhood', axis=1)\n",
    "        )\n",
    "        neighbourhoods_to_keep.to_csv('data/neighbourhoods_to_keep.csv')\n",
    "        \n",
    "    df = (\n",
    "        df\n",
    "        .merge(neighbourhoods_to_keep, how='left', left_on='neighbourhood', right_on='neighbourhood_to_keep')\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "        \n",
    "def fill_na(df: pd.DataFrame, replacements: dict) -> pd.DataFrame:\n",
    "    for k, v in replacements.items():\n",
    "\n",
    "        if callable(v):\n",
    "            value = v(df[k])\n",
    "        else:\n",
    "            value = v\n",
    "        \n",
    "        local_kwargs = {k : lambda df: df[k].fillna(value)}\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .assign(**local_kwargs)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df = pd.get_dummies(\n",
    "        df, columns=columns, prefix='', prefix_sep=''\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_host_response_rate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = (\n",
    "        df\n",
    "        .assign(host_response_rate=lambda df: df.host_response_rate.str.replace('%', '').astype(float))\n",
    "        .assign(host_response_class=lambda df: pd.cut(df.host_response_rate, \n",
    "                                                    bins=[0, 75, 80, 85, 90, 95, 100.00], \n",
    "                                                    labels=['very_low',\n",
    "                                                            'low',\n",
    "                                                            'medium',\n",
    "                                                            'high',\n",
    "                                                            'very_high',\n",
    "                                                            'best'], \n",
    "                                                    include_lowest=True))\n",
    "        .assign(host_response_class=lambda df: df.host_response_class.cat.add_categories('other').fillna('other'))\n",
    "        .drop('host_response_rate', axis=1)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_review_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = (\n",
    "    df\n",
    "        .assign(first_review=lambda df: pd.to_datetime(df.first_review))\n",
    "        .assign(last_review=lambda df: pd.to_datetime(df.last_review))\n",
    "        .assign(host_since=lambda df: pd.to_datetime(df.host_since))\n",
    "        .assign(today=[date.today()]*len(df.index))\n",
    "        .assign(today=lambda df: pd.to_datetime(df.today))\n",
    "        .assign(days_since_first_review=lambda df: (df.today - df.first_review).dt.days)\n",
    "        .assign(days_since_last_review=lambda df: (df.today - df.last_review).dt.days)\n",
    "        .assign(days_host_since=lambda df: (df.today - df.host_since).dt.days)\n",
    "        .assign(first_review_class=lambda df: pd.cut(df.days_since_first_review, \n",
    "                                                    bins=[0, 1095, 1280, 1460, 1645, 1830, max(df.days_since_first_review)], \n",
    "                                                    labels=['0y-3y',\n",
    "                                                            '3y-3y6m',\n",
    "                                                            '3y6m-4y',\n",
    "                                                            '4y-4y6m',\n",
    "                                                            '4y6m-5y',\n",
    "                                                            '5y'], \n",
    "                                                    include_lowest=True))\n",
    "        .assign(last_review_class=lambda df: pd.cut(df.days_since_last_review, \n",
    "                                                    bins=[0, 1095, 1220, 1460, 1645, 1830, max(df.days_since_first_review)], \n",
    "                                                    labels=['0y-3y',\n",
    "                                                            '3y-3y6m',\n",
    "                                                            '3y6m-4y',\n",
    "                                                            '4y-4y6m',\n",
    "                                                            '4y6m-5y',\n",
    "                                                            '5y'], \n",
    "                                                    include_lowest=True))\n",
    "        .assign(first_review_class=lambda df: df.first_review_class.cat.add_categories('other').fillna('other'))\n",
    "        .assign(last_review_class=lambda df: df.last_review_class.cat.add_categories('other').fillna('other'))\n",
    "        .assign(days_host_since=lambda df: df.days_host_since.fillna(1))\n",
    "        .drop(['first_review', 'last_review', 'today', 'days_since_first_review', 'days_since_last_review', 'host_since'], axis=1)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_amenities(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    amenities_to_keep = []\n",
    "    \n",
    "    if os.path.isfile('data/amenities_to_keep'):\n",
    "        print('process_amenities -> reading amenities_to_keep from file')\n",
    "        with open('data/amenities_to_keep', 'r') as f: \n",
    "            reader = csv.reader(f)\n",
    "\n",
    "            for row in reader:\n",
    "                amenities_to_keep = row\n",
    "            \n",
    "    if not amenities_to_keep:\n",
    "        print('process_amenities -> processing amenities_to_keep')\n",
    "        amenities = [x.strip() for x in \", \".join(list(df.amenities)).replace('{', '').replace('}', '').replace('\"', '').replace('TV', '').split(',')]\n",
    "\n",
    "        amenities_counter = {}\n",
    "        for amenity in amenities:\n",
    "            if amenity in amenities_counter.keys():\n",
    "                amenities_counter[amenity] += 1\n",
    "            else:\n",
    "                amenities_counter[amenity] = 1\n",
    "\n",
    "        amenities_counter_sorted = {k: v for k, v in sorted(amenities_counter.items(), key=lambda item: item[1])}\n",
    "\n",
    "        amenities_to_keep = []\n",
    "        records_count = (len(amenities_counter_sorted) + 0.001)\n",
    "        for i, e in (enumerate(amenities_counter_sorted.items())):\n",
    "            if (i*100.0/records_count > 20 or i*100.0/records_count < 80) \\\n",
    "            and (e[1] > 2) \\\n",
    "            and (\"translation missing\" not in e[0]) \\\n",
    "            and (e[0] != ''):\n",
    "                amenities_to_keep.append(e[0])\n",
    "                \n",
    "        with open('data/amenities_to_keep', 'w') as f: \n",
    "            print('process_amenities -> writing amenities_to_keep to file')\n",
    "            write = csv.writer(f) \n",
    "            write.writerow(amenities_to_keep)\n",
    "                \n",
    "        \n",
    "            \n",
    "    for amenity in amenities_to_keep:\n",
    "        df[amenity] = df.apply(lambda row: 1 if amenity in row.amenities else 0, axis=1)\n",
    "        \n",
    "    df = df.drop(['amenities'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_property_type(df: pd.DataFrame, column: str, replacements: dict) -> pd.DataFrame:\n",
    "    local_kwargs = {column : lambda df: df[column].replace(replacements)}\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .assign(**local_kwargs)\n",
    "    )\n",
    "    \n",
    "    df.loc[~df.property_type.isin(['House', 'Apartment']), 'property_type'] = 'other'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_amenities -> reading amenities_to_keep from file\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['neighbourhood'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-80f00a103cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                        \u001b[0;34m'neighbourhood'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                        \u001b[0;34m'property_type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                        'neighbourhood_to_keep'])\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pipe'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4259\u001b[0m     _shared_docs['aggregate'] = (\"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_pipe\u001b[0;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9db1238770d7>\u001b[0m in \u001b[0;36mone_hot_encoder\u001b[0;34m(df, columns)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_hot_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     df = pd.get_dummies(\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 include=dtypes_to_encode)\n\u001b[1;32m    843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['neighbourhood'] not in index\""
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train = (\n",
    "    df_train\n",
    "        .pipe(drop_features, columns=['latitude', 'longitude', 'name', 'thumbnail_url', 'zipcode', 'host_has_profile_pic', 'description'])\n",
    "        .pipe(fill_na, replacements={'neighbourhood': 'other'})\n",
    "        .pipe(process_neighbourhoods, quantile=0.8)\n",
    "        .pipe(drop_features, columns=['neighbourhood'])\n",
    "        .pipe(fill_na, replacements={'number_of_reviews': 0,\n",
    "                                     'bedrooms': 0,\n",
    "                                     'review_scores_rating': mean,\n",
    "                                     'beds': median,\n",
    "                                     'bathrooms': median,\n",
    "                                     'accommodates': median,\n",
    "                                     'neighbourhood_to_keep': 'other'})\n",
    "        .pipe(bool_to_binary, columns=['cleaning_fee', 'host_identity_verified', 'instant_bookable'])\n",
    "        .pipe(process_property_type, column='property_type', replacements={'Townhouse': 'House',\n",
    "                                                                           'Bungalow': 'House',\n",
    "                                                                           'Cottage': 'House',\n",
    "                                                                           'Villa': 'House',\n",
    "                                                                           'Tiny house': 'House',\n",
    "                                                                           'Chalet': 'House',\n",
    "                                                                           'Serviced apartment': 'Apartment',\n",
    "                                                                           'Loft': 'Apartment',\n",
    "                                                                           'Condominium': 'Apartment'})\n",
    "        .pipe(process_host_response_rate)\n",
    "        .pipe(process_review_dates)\n",
    "        .pipe(process_amenities)\n",
    "        .pipe(one_hot_encoder, \n",
    "              columns=['instant_bookable', \n",
    "                       'host_identity_verified', \n",
    "                       'city', \n",
    "                       'cleaning_fee',\n",
    "                       'cancellation_policy', \n",
    "                       'bed_type', \n",
    "                       'room_type', \n",
    "                       'host_response_class', \n",
    "                       'neighbourhood', \n",
    "                       'property_type',\n",
    "                       'neighbourhood_to_keep'])\n",
    "\n",
    ")\n",
    "\n",
    "df_train.to_csv('data/train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed = pd.read_csv('data/train_processed.csv')\n",
    "df_train_processed.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
